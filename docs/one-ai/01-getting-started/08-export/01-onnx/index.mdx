---
title: Integrate Generated AI Models
sidebar_label: Integrate Generated AI Models
---

import Link from '@docusaurus/Link';

# Integrate ONE AI Models (ONNX / TensorFlow Lite)

This guide explains how to use the AI models generated by ONE AI after export. ONE AI can export models in **ONNX** and **TensorFlow Lite** formats, which can be integrated into virtually any application or platform.

## Export Settings

When exporting your model, make sure to enable **"Include Pre- and Postprocessing"** in the export options. This simplifies integration by embedding all necessary preprocessing (normalization, resizing) and postprocessing (result interpretation) directly into the model.

<div style={{ display: 'flex', justifyContent: 'center', marginBottom: '2rem' }}>
    <img src="/img/ai/one_ai_plugin/getting_started/export_2.png" alt="Enable Pre- and Postprocessing" style={{ maxWidth: '600px', width: '100%' }} />
</div>

---

## Input Format

### Single Image Input

When your model uses a single image as input, the input tensor has the following shape:

```
[1, height, width, 3]
```

| Dimension | Description |
|-----------|-------------|
| `1` | Batch size (always 1 for inference) |
| `height` | Image height in pixels (as configured during training) |
| `width` | Image width in pixels (as configured during training) |
| `3` | RGB color channels |

**Data Type:** `float32` with values in range `[0, 255]` (when pre-processing is included)

### Multiple Image Input

For models that compare multiple images (e.g., difference detection), the input tensor shape is:

```
[1, height, width, 3, image_count]
```

| Dimension | Description |
|-----------|-------------|
| `1` | Batch size (always 1 for inference) |
| `height` | Image height in pixels |
| `width` | Image width in pixels |
| `3` | RGB color channels |
| `image_count` | Number of input images |

---

## Output Format

The output format depends on the task type configured during training.

### Classification

For image classification tasks, the output tensor has the shape:

```
[1, detected_classes, 2]
```

| Index | Description |
|-------|-------------|
| `0` | Confidence value (0.0 - 1.0) |
| `1` | Class ID |

**Example Output:**
```json
[[0.95, 0], [0.03, 1], [0.02, 2]]
```
This means: Class 0 with 95% confidence, Class 1 with 3% confidence, Class 2 with 2% confidence.

### Object Detection

For object detection tasks, the output tensor has the shape:

```
[1, detected_objects, 6]
```

| Index | Description |
|-------|-------------|
| `0` | X center (in pixels, relative to model input size) |
| `1` | Y center (in pixels, relative to model input size) |
| `2` | Width (in pixels) |
| `3` | Height (in pixels) |
| `4` | Confidence value (0.0 - 1.0) |
| `5` | Class ID |

**Example Output:**
```json
[[128, 96, 64, 48, 0.92, 1]]
```
This means: Object of Class 1 at center position (128px, 96px) with size (64px Ã— 48px) and 92% confidence.

:::warning Important: Coordinate Reference
The pixel coordinates in the output refer to the **model's input dimensions**, not your original image size. If you resize or crop your image before feeding it into the model, you need to transform the coordinates back to your original image space.
:::

### Segmentation

For semantic segmentation tasks, the output tensor has the shape:

```
[1, height, width, 1]
```

Each pixel position contains the predicted **Class ID** for that location.

**Example:** A 256x256 segmentation output would be a tensor of shape `[1, 256, 256, 1]` where each value represents the class at that pixel.

---

## Integration Options

### C# SDK (Recommended for .NET Applications)

We provide a ready-to-use C# SDK that handles all the complexity of model loading, inference, and result parsing:

<div className="text--center" style={{ display: 'flex', justifyContent: 'center', gap: '1rem', flexWrap: 'wrap', marginBottom: '1.5rem' }}>
  <Link className="button button--primary button--lg" href="/docs/one-ai/getting-started/export/onnx/csharp">
    <p className="m-0 p-0">C# SDK Documentation</p>
  </Link>
</div>

### C++ Project or Executable

For deployment on embedded systems, servers, or when you need maximum performance, ONE AI can export a complete **C++ project** or **precompiled executable** based on TensorFlow Lite:

<div className="text--center" style={{ display: 'flex', justifyContent: 'center', gap: '1rem', flexWrap: 'wrap', marginBottom: '1.5rem' }}>
  <Link className="button button--primary button--lg" href="/docs/one-ai/getting-started/export">
    <p className="m-0 p-0">C++ Export Guide</p>
  </Link>
  <Link className="button button--primary button--lg" href="/docs/one-ai/getting-started/export/documentation-cpp-api">
    <p className="m-0 p-0">C++ API Documentation</p>
  </Link>
</div>

### Direct Integration

For custom integrations, you can use the standard ONNX or TensorFlow Lite runtimes:

#### ONNX Runtime

- **Python:** [ONNX Runtime Python Documentation](https://onnxruntime.ai/docs/get-started/with-python)
- **C++:** [ONNX Runtime C++ API](https://onnxruntime.ai/docs/get-started/with-cpp)
- **C#:** [ONNX Runtime C# API](https://onnxruntime.ai/docs/get-started/with-csharp)
- **JavaScript:** [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript)
- **Others:** [ONNX Runtime](https://onnxruntime.ai/docs/get-started/)

#### TensorFlow Lite

- **Python:** [TFLite Python API](https://www.tensorflow.org/api_docs/python/tf/lite/Interpreter)
- **C++:** [LiteRT for Microcontrollers](https://ai.google.dev/edge/litert/microcontrollers)
- **JavaScript:** [LiteRT Web](https://ai.google.dev/edge/litert/web)
- **Android:** [LiteRT Android Guide](https://ai.google.dev/edge/litert/android)
- **iOS:** [LiteRT iOS Quickstart](https://ai.google.dev/edge/litert/ios/quickstart)