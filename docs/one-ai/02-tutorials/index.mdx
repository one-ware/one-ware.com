---
id: tutorials
title: Tutorial Overview
---

import Link from '@docusaurus/Link';
import LiteYouTubeEmbed from '@site/src/components/LiteYouTubeEmbed';

## Getting Started & Setup
<div style={{ marginBottom: '2rem' }}>
  <LiteYouTubeEmbed 
    videoId="A7_Ylca_HfQ"
    previewImage="/img/demos/thumbnail.jpg"
    title="Getting Started with ONE AI"
  />
</div>

<div style={{ display: 'flex', justifyContent: 'center', gap: '1rem', flexWrap: 'wrap', marginBottom: '2rem' }}>
    <img src="/img/ai/one_ai_plugin/demos/overview_flowchart.png" alt="chips_example_non-defective_01" style={{ width: '85%' }} />
</div>

We have several tutorials on our website that show you how to use ONE AI to complete a single project. Here is a short overview.

## Teacup Print Detection 
[This demo](/docs/one-ai/tutorials/teacup-print-detection) walks you through building a simple object detection model for recognizing a printed logo on a teacup using only a small and highly varied dataset. You learn how to prepare and annotate the images, apply effective prefilters and augmentations, and configure the model for robust detection. The guide also explains how to train, test, and export the final model for further use.

<div style={{ marginBottom: '2rem' }}>
  <LiteYouTubeEmbed 
    videoId="WrpJOOlnPsM"
    previewImage="/img/ai/one_ai_plugin/demos/tea_cup_print/preview.jpg"
    title="Teacup Print Detection Demo"
  />
</div>

<div className="text--center" style={{ display: 'flex', justifyContent: 'center', gap: '1rem', flexWrap: 'wrap' }}>
  <Link className="button button--primary button--lg" href="/docs/one-ai/tutorials/teacup-print-detection">
    <p className="m-0 p-0">Check out Demo</p>
  </Link>
  <Link className="button button--primary button--lg" href="https://github.com/one-ware/OneAI_demo_datasets/blob/main/projects/teacup_print_detection.zip" target="_blank" rel="noopener noreferrer">
    <p className="m-0 p-0">Download Project & Dataset</p>
  </Link>
  <Link className="button button--primary button--lg" href="https://www.youtube.com/watch?v=vN1ZBED_aDU" target="_blank" rel="noopener noreferrer">
    <p className="m-0 p-0">Watch the Webinar</p>
  </Link>
</div>

## Quality control for potato chips
[This demo](/docs/one-ai/tutorials/potato-chip-demo) is a good introduction to ONE AI. It shows you how you can use ONE AI for quality control by guiding you through the process of creating an AI model that classifies potato chips as good and defective. This tutorial focuses on the basic functions of ONE AI and explains them in more detail than the later tutorials.

<div style={{ marginBottom: '2rem' }}>
  <LiteYouTubeEmbed 
    videoId="A7_Ylca_HfQ"
    previewImage="/img/ai/one_ai_plugin/use_cases/chip/defect.png"
    title="Potato Chip Classification Demo"
  />
</div>

<div className="text--center" style={{ display: 'flex', justifyContent: 'center', gap: '1rem', flexWrap: 'wrap' }}>
  <Link className="button button--primary button--lg" href="/docs/one-ai/tutorials/potato-chip-demo">
    <p className="m-0 p-0">Check out Demo</p>
  </Link>
  <Link className="button button--primary button--lg" href="https://github.com/one-ware/OneAI_demo_datasets/blob/main/projects/Chips.zip" target="_blank" rel="noopener noreferrer">
    <p className="m-0 p-0">Download Project</p>
  </Link>
</div>

## Reference-Based Object Detection for Birds and Drones
[This demo](/docs/one-ai/tutorials/difference-image-demo) shows how you can use ONE AI to create an AI model that detects and classifies small objects by comparing test images to reference templates. The tutorial explains all relevant settings for configuring the model and demonstrates how multi-image comparison (overlap difference) enables robust detection even in complex backgrounds.
<div style={{ display: 'flex', gap: '1rem', flexWrap: 'wrap', marginBottom: '2rem' }}>
    <img src="/img/ai/one_ai_plugin/demos/overlap-difference/image_000118_temp.png" alt="image_000118_temp" style={{ width: '48%' }} />
    <img src="/img/ai/one_ai_plugin/demos/overlap-difference/image_000118_test.png" alt="image_000118_test" style={{ width: '48%' }} />
</div>

<div className="text--center" style={{ display: 'flex', justifyContent: 'center', gap: '1rem', flexWrap: 'wrap' }}>
  <Link className="button button--primary button--lg" href="/docs/one-ai/tutorials/difference-image-demo">
    <p className="m-0 p-0">Check out Demo</p>
  </Link>
  <Link className="button button--primary button--lg" href="https://github.com/one-ware/OneAI_demo_datasets/blob/main/projects/DronesAndBirds.zip" target="_blank" rel="noopener noreferrer">
    <p className="m-0 p-0">Download Project & Dataset</p>
  </Link>
</div>

## Handwritten digit classification
[This demo](/docs/one-ai/tutorials/handwritten-digits-demo) shows how you can use ONE AI to create an AI model that classifies handwritten digits. It explains all the settings that are important to configuring the model and even shows you how you can test the trained model with your webcam. The tutorial also has a section that explains how using a varied dataset can improve the performance of your model.

![nist_sd19_examples](/img/ai/one_ai_plugin/demos/handwritten-digits/nist_sd19_examples.jpg)

<div className="text--center" style={{ display: 'flex', justifyContent: 'center', gap: '1rem', flexWrap: 'wrap' }}>
  <Link className="button button--primary button--lg" href="/docs/one-ai/tutorials/handwritten-digits-demo">
    <p className="m-0 p-0">Check out Demo</p>
  </Link>
  <Link className="button button--primary button--lg" href="https://github.com/one-ware/OneAI_demo_datasets/blob/main/projects/NIST_SD19.zip" target="_blank" rel="noopener noreferrer">
    <p className="m-0 p-0">Download Project</p>
  </Link>
</div>

## VHDL Project Demo
[This demo](/docs/one-ai/tutorials/vhdl-demo) showcases how to run a OneAI model on an FPGA for a demo use case. The use case will be the classification of handwritten digits. It demonstrates how to test AI on any FPGA, regardless of manufacturer and type, by sending images via UART and receiving results back. You can identify your own handwritten digits using an FPGA board of your choosing and the webcam of your computer.

![Classification Result](/img/ai/one_ai_plugin/tutorials/vhdl_stream_screenshot.jpg)

<div className="text--center" style={{ display: 'flex', justifyContent: 'center', gap: '1rem', flexWrap: 'wrap' }}>
  <Link className="button button--primary button--lg" href="/docs/one-ai/tutorials/vhdl-demo">
    <p className="m-0 p-0">Check out Demo</p>
  </Link>
</div>

## Quality control for building defects
[This demo](/docs/one-ai/tutorials/bd3-building-defects-detection-demo) outlines the complete porcess of developing a classification model for building defects, using ONE AI. You will learn how to handle such a large dataset and use prefilters and augmentations to get results, which can compete with state-of-the-art computer vision approaches.  
<div style={{ display: 'flex', justifyContent:'center', gap: '1rem', flexWrap: 'wrap', marginBottom: '20px' }}>
    <img src="/img/ai/one_ai_plugin/demos/bd3-building-defects/example1.jpg" alt="example1" style={{ width: '30%' }} />
    <img src="/img/ai/one_ai_plugin/demos/bd3-building-defects/example2.jpg" alt="example2" style={{ width: '30%' }} />
    <img src="/img/ai/one_ai_plugin/demos/bd3-building-defects/example3.jpg" alt="example3" style={{ width: '30%' }} />
</div>

<div className="text--center" style={{ display: 'flex', justifyContent: 'center', gap: '1rem', flexWrap: 'wrap' }}>
  <Link className="button button--primary button--lg" href="/docs/one-ai/tutorials/bd3-building-defects-detection-demo">
    <p className="m-0 p-0">Check out Demo</p>
  </Link>
  <Link className="button button--primary button--lg" href="https://onewarecom.sharepoint.com/:u:/s/Public/IQBqxmnKGzERQrz865UMxdpMAbz7VJhCHSP_hbEXdB29QDY?e=saGHWP" target="_blank" rel="noopener noreferrer">
    <p className="m-0 p-0">Download Project</p>
  </Link>
</div>